# .env.template

# Choose your LLM backend: openai or ollama
LLM_BACKEND=ollama 

# OpenAI Configuration
OPENAI_API_KEY=<your-openai-api-key>
OPENAI_MODEL=gpt-4o

# Ollama Configuration
OLLAMA_HOST_URL=http://localhost:11434
# Change this to any other supported Ollama models available locally.
OLLAMA_MODEL=gemma3:1b

